{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Credit Card Fraud Detection using Scikit-Learn and Snap ML**\n",
    "\n",
    "\n",
    "**Détection des fraudes à la carte de crédit à l'aide de Scikit-Learn et Snap ML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise session you will consolidate your machine learning (ML) modeling skills by using two popular classification models to recognize fraudulent credit card transactions. These models are: Decision Tree and Support Vector Machine. You will use a real dataset to train each of these models. The dataset includes information about \n",
    "transactions made by credit cards in September 2013 by European cardholders. You will use the trained model to assess if a credit card transaction is legitimate or not.\n",
    "\n",
    "In the current exercise session, you will practice not only the Scikit-Learn Python interface, but also the Python API offered by the Snap Machine Learning (Snap ML) library. Snap ML is a high-performance IBM library for ML modeling. It provides highly-efficient CPU/GPU implementations of linear models and tree-based models. Snap ML not only accelerates ML algorithms through system awareness, but it also offers novel ML algorithms with best-in-class accuracy. For more information, please visit [snapml](https://ibm.biz/BdPfxy) information page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette session d'exercices, vous consoliderez vos compétences en modélisation de l'apprentissage machine (ML) en utilisant deux modèles de classification populaires pour reconnaître les transactions de cartes de crédit frauduleuses. Ces modèles sont : L'arbre de décision et la machine à vecteur de support. Vous utiliserez un ensemble de données réelles pour entraîner chacun de ces modèles. L'ensemble de données comprend des informations sur \n",
    "transactions effectuées par cartes de crédit en septembre 2013 par des titulaires de cartes européens. Vous utiliserez le modèle formé pour évaluer si une transaction par carte de crédit est légitime ou non.\n",
    "\n",
    "Dans cette session d'exercices, vous pratiquerez non seulement l'interface Python de Scikit-Learn, mais aussi l'API Python offerte par la bibliothèque Snap Machine Learning (Snap ML). Snap ML est une bibliothèque IBM haute performance pour la modélisation ML. Elle fournit des implémentations CPU/GPU très efficaces de modèles linéaires et de modèles à base d'arbres. Snap ML ne se contente pas d'accélérer les algorithmes de ML grâce à la connaissance du système, mais propose également de nouveaux algorithmes de ML avec la meilleure précision de leur catégorie. Pour plus d'informations, veuillez consulter la page d'information [snapml](https://ibm.biz/BdPfxy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform basic data preprocessing in Python\n",
    "* Model a classification task using the Scikit-Learn and Snap ML Python APIs\n",
    "* Train Suppport Vector Machine and Decision Tree models using Scikit-Learn and Snap ML\n",
    "* Run inference and assess the quality of the trained models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Effectuer le prétraitement de base des données en Python\n",
    "* Modéliser une tâche de classification à l’aide des API Python Scikit-Learn et Snap ML\n",
    "* Entraînez des modèles de machines vectorielles et d’arbres de décision à l’aide de Scikit-Learn et Snap ML\n",
    "* Exécuter l’inférence et évaluer la qualité des modèles entraînés\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alerte alerte-bloc alerte-info » style=\"margin-top : 10px\">\n",
    "    <ol>\n",
    "\n",
    "<li><a href=\"#introduction\">Introduction</a></li>\n",
    "        <li><a href=\"#import_libraries\">Importer des bibliothèques</a></li>\n",
    "        <li><a href=\"#dataset_analysis\">Analyse des ensembles de données</a></li>\n",
    "        <li><a href=\"#dataset_preprocessing\">Prétraitement des ensembles de données</a></li>\n",
    "        <li><a href=\"#dataset_split\">Répartition train/test du jeu de données</a></li>\n",
    "        <li><a href=\"#dt_sklearn\">Construisez un modèle de classificateur d’arbre de décision avec Scikit-Learn</a></li>\n",
    "        <li><a href=\"#dt_snap\">Construire un modèle de classificateur d’arbre de décision avec Snap ML</a></li>\n",
    "        <li><a href=\"#dt_sklearn_snap\">Évaluer les classificateurs d’arbre de décision Scikit-Learn et Snap ML</a></li>\n",
    "        <li><a href=\"#svm_sklearn\">Construisez un modèle de machine à vecteurs de support avec Scikit-Learn</a></li>\n",
    "        <li><a href=\"#svm_snap\">Construire un modèle de machine à vecteurs de support avec Snap ML</a></li>\n",
    "        <li><a href=\"#svm_sklearn_snap\">Évaluer les modèles de machine à vecteurs de support Scikit-Learn et Snap ML</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 10px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#introduction\">Introduction</a></li>\n",
    "        <li><a href=\"#import_libraries\">Import Libraries</a></li>\n",
    "        <li><a href=\"#dataset_analysis\">Dataset Analysis</a></li>\n",
    "        <li><a href=\"#dataset_preprocessing\">Dataset Preprocessing</a></li>\n",
    "        <li><a href=\"#dataset_split\">Dataset Train/Test Split</a></li>\n",
    "        <li><a href=\"#dt_sklearn\">Build a Decision Tree Classifier model with Scikit-Learn</a></li>\n",
    "        <li><a href=\"#dt_snap\">Build a Decision Tree Classifier model with Snap ML</a></li>\n",
    "        <li><a href=\"#dt_sklearn_snap\">Evaluate the Scikit-Learn and Snap ML Decision Tree Classifiers</a></li>\n",
    "        <li><a href=\"#svm_sklearn\">Build a Support Vector Machine model with Scikit-Learn</a></li>\n",
    "        <li><a href=\"#svm_snap\">Build a Support Vector Machine model with Snap ML</a></li>\n",
    "        <li><a href=\"#svm_sklearn_snap\">Evaluate the Scikit-Learn and Snap ML Support Vector Machine Models</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Introduction\">\n",
    "    <h2>Introduction</h2>\n",
    "    <br>Imagine that you work for a financial institution and part of your job is to build a model that predicts if a credit card transaction is fraudulent or not. You can model the problem as a binary classification problem. A transaction belongs to the positive class (1) if it is a fraud, otherwise it belongs to the negative class (0).\n",
    "    <br>\n",
    "    <br>You have access to transactions that occured over a certain period of time. The majority of the transactions are normally legitimate and only a small fraction are non-legitimate. Thus, typically you have access to a dataset that is highly unbalanced. This is also the case of the current dataset: only 492 transactions out of 284,807 are fraudulent (the positive class - the frauds - accounts for 0.172% of all transactions).\n",
    "    <br>\n",
    "    <br>This is a Kaggle dataset. You can find this \"Credit Card Fraud Detection\" dataset from the following link: <a href=\"https://www.kaggle.com/mlg-ulb/creditcardfraud\">Credit Card Fraud Detection</a>.\n",
    "<br>\n",
    "    <br>To train the model, you can use part of the input dataset, while the remaining data can be utilized to assess the quality of the trained model. First, let's import the necessary libraries and download the dataset.\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "\n",
    "\n",
    "Imaginez que vous travaillez pour une institution financière et qu'une partie de votre travail consiste à élaborer un modèle permettant de prédire si une transaction par carte de crédit est frauduleuse ou non. Vous pouvez modéliser le problème comme un problème de classification binaire. Une transaction appartient à la classe positive (1) s'il s'agit d'une fraude, sinon elle appartient à la classe négative (0).\n",
    "\n",
    "Vous avez accès aux transactions qui se sont produites au cours d'une certaine période. La majorité des transactions sont normalement légitimes et seule une petite fraction est non légitime. Ainsi, vous avez généralement accès à un ensemble de données fortement déséquilibré. C'est également le cas de l'ensemble de données actuel : seules 492 transactions sur 284 807 sont frauduleuses (la classe positive - les fraudes - représente 0,172 % de toutes les transactions).\n",
    "\n",
    "Il s'agit d'un ensemble de données Kaggle. Vous pouvez trouver cet ensemble de données « Credit Card Fraud Detection » à partir du lien suivant : Credit Card Fraud Detection.\n",
    "\n",
    "Pour entraîner le modèle, vous pouvez utiliser une partie de l'ensemble de données d'entrée, tandis que les données restantes peuvent être utilisées pour évaluer la qualité du modèle entraîné. Tout d'abord, importons les bibliothèques nécessaires et téléchargeons l'ensemble de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"import_libraries\">\n",
    "    <h2>Import Libraries</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.2\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-learn==1.0.2) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-learn==1.0.2) (1.7.3)\n",
      "Collecting joblib>=0.11 (from scikit-learn==1.0.2)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn==1.0.2)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.20.1\n",
      "    Uninstalling scikit-learn-0.20.1:\n",
      "      Successfully uninstalled scikit-learn-0.20.1\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.0.2 threadpoolctl-3.1.0\n",
      "Collecting snapml\n",
      "  Downloading snapml-1.14.0-cp37-cp37m-manylinux2014_x86_64.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml) (1.0.2)\n",
      "Requirement already satisfied: scipy in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from snapml) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-learn->snapml) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-learn->snapml) (3.1.0)\n",
      "Installing collected packages: snapml\n",
      "Successfully installed snapml-1.14.0\n"
     ]
    }
   ],
   "source": [
    "# Install scikit-learn using pip\n",
    "!pip install scikit-learn==1.0.2\n",
    "\n",
    "# Snap ML is available on PyPI. To install it simply run the pip command below.\n",
    "!pip install snapml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the libraries we need to use in this lab\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salut Rodriguezmahi\n",
    "\n",
    "Merci pour votre message ! Nous serons heureux de vous aider.\n",
    "\n",
    "Examinons ce code en détail pour comprendre le but et la fonctionnalité de chaque partie.\n",
    "\n",
    "1. à partir de __future__ importer print_function\n",
    "\n",
    "En incluant from __future__ import print_function, le code Python 2 peut utiliser la syntaxe Python 3 pour print en tant que fonction. Cela est utile lors de l'écriture de code qui doit s'exécuter dans les deux versions de Python.\n",
    "\n",
    "2. à partir de l'importation sklearn.utils.class_weight\n",
    "\n",
    "Compute_sample_weightCompute_sample_weight : cette fonction permet d'attribuer des pondérations à des échantillons individuels en fonction de leur classe. Elle est particulièrement importante lorsqu'il s'agit d'ensembles de données déséquilibrés, où certaines classes sont sous-représentées. En attribuant des pondérations plus élevées à la classe minoritaire, vous aidez le modèle à la traiter avec la même importance. .\n",
    "\n",
    "Cela garantit que le modèle prend en compte les déséquilibres de classe et ne favorise pas la classe majoritaire lors de la formation.\n",
    "\n",
    "3. depuis sklearn.metrics importer roc_auc_score\n",
    "\n",
    "roc_auc_score : cette mesure calcule l' aire sous la courbe caractéristique de fonctionnement du récepteur (ROC-AUC) . Elle est couramment utilisée dans les problèmes de classification binaire pour évaluer les performances du modèle. Le score ROC-AUC varie de 0 à 1, un score plus proche de 1 étant possible. indique de meilleures performances.\n",
    "\n",
    "4. import timetime : Ce module est utilisé pour mesurer le temps, souvent pour le profilage des performances. Par exemple, vous pouvez utiliser time.time() pour enregistrer les heures de début et de fin d'une fonction afin de calculer le temps d'exécution (c'est-à-dire la durée de l'exécution). le code prend pour s'exécuter).\n",
    "\n",
    "5. Avertissements d'importation\n",
    "\n",
    "warnings : Le module warnings permet de contrôler les messages d'avertissement générés par Python. Parfois, lors de l'entraînement ou de l'évaluation d'un modèle, vous pouvez rencontrer des avertissements liés à des dépréciations ou à des performances. Ces avertissements n'arrêtent pas nécessairement le programme mais peuvent encombrer la sortie.\n",
    "\n",
    "5. à partir de sklearn.preprocessing, importer normaliser, StandardScaler\n",
    "\n",
    "normaliser : Cette fonction est utilisée pour normaliser les vecteurs de caractéristiques afin qu'ils aient une norme spécifique (par exemple, L1 ou L2). Elle met à l'échelle les données de sorte que la somme des valeurs absolues (pour L1) ou la somme des carrés (pour L2) ) est égal à 1 pour chaque échantillon. La normalisation est utile lorsque vous souhaitez rendre les entités comparables en termes de magnitude, en particulier dans les modèles basés sur la distance ou linéaires.\n",
    "\n",
    "StandardScaler : Cela normalise les fonctionnalités en supprimant la moyenne et en mettant à l'échelle la variance unitaire. Chaque fonctionnalité aura une moyenne de 0 et un écart type de 1. La normalisation aide les modèles sensibles à la mise à l'échelle des fonctionnalités (tels que les machines à vecteurs de support, la régression logistique, et les réseaux neuronaux).\n",
    "\n",
    "Résumé de l'objectif du code :\n",
    "\n",
    "Compatibilité (de __future__ import print_function) : Assure la compatibilité entre Python 2 et 3.\n",
    "\n",
    "Prétraitement (normaliser, StandardScaler) : Ces fonctions aident à normaliser ou à standardiser les données d'entrée, les rendant adaptées aux algorithmes d'apprentissage automatique.\n",
    "\n",
    "Gestion des déséquilibres de classe (compute_sample_weight) : attribue des poids aux échantillons en fonction des déséquilibres de classe, garantissant ainsi que le modèle traite toutes les classes de manière équitable.\n",
    "\n",
    "Évaluation du modèle (roc_auc_score) : mesure les performances des modèles de classification binaire à l'aide du score AUC.\n",
    "\n",
    "Timing (temps) : Mesure le temps nécessaire à l'exécution du code, souvent utilisé pour profiler et optimiser les performances.\n",
    "\n",
    "Avertissements (warnings.filterwarnings('ignore')) : supprime les avertissements pour conserver la sortie\n",
    "\n",
    "Bon apprentissage !\n",
    "\n",
    "Salutations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 284807 observations in the credit card fraud dataset.\n",
      "There are 31 variables in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "url= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/creditcard.csv\"\n",
    "\n",
    "# read the input data\n",
    "raw_data=pd.read_csv(url)\n",
    "print(\"There are \" + str(len(raw_data)) + \" observations in the credit card fraud dataset.\")\n",
    "print(\"There are \" + str(len(raw_data.columns)) + \" variables in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dataset_analysis\">\n",
    "    <h2>Dataset Analysis</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will read the dataset in a Pandas dataframe and visualize its content. You will also look at some data statistics. \n",
    "\n",
    "Note: A Pandas dataframe is a two-dimensional, size-mutable, potentially heterogeneous tabular data structure. For more information: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, vous lirez l'ensemble de données dans un cadre de données Pandas et visualiserez son contenu. Vous examinerez également quelques statistiques sur les données. \n",
    "\n",
    "Remarque : un cadre de données Pandas est une structure de données tabulaires bidimensionnelle, de taille variable et potentiellement hétérogène. Pour plus d'informations : https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first rows in the dataset\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, a financial institution may have access to a much larger dataset of transactions. To simulate such a case, we will inflate the original one 10 times.\n",
    "\n",
    "\n",
    "Dans la pratique, une institution financière peut avoir accès à un ensemble de données de transactions beaucoup plus important. Pour simuler un tel cas, nous allons gonfler l'original 10 fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2848070 observations in the inflated credit card fraud dataset.\n",
      "There are 31 variables in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "2   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "3   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "4   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "2  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "3  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "4  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "2 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "3 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "4 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_replicas = 10\n",
    "\n",
    "# inflate the original dataset\n",
    "big_raw_data = pd.DataFrame(np.repeat(raw_data.values, n_replicas, axis=0), columns=raw_data.columns)\n",
    "\n",
    "print(\"There are \" + str(len(big_raw_data)) + \" observations in the inflated credit card fraud dataset.\")\n",
    "print(\"There are \" + str(len(big_raw_data.columns)) + \" variables in the dataset.\")\n",
    "\n",
    "# display first rows in the new dataset\n",
    "big_raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset represents a credit card transaction. As shown above, each row has 31 variables. One variable (the last variable in the table above) is called Class and represents the target variable. Your objective will be to train a model that uses the other variables to predict the value of the Class variable. Let's first retrieve basic statistics about the target variable.\n",
    "\n",
    "Note: For confidentiality reasons, the original names of most features are anonymized V1, V2 .. V28. The values of these features are the result of a PCA transformation and are numerical. The feature 'Class' is the target variable and it takes two values: 1 in case of fraud and 0 otherwise. For more information about the dataset please visit this webpage: https://www.kaggle.com/mlg-ulb/creditcardfraud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque ligne de l’ensemble de données représente une transaction par carte de crédit. Comme indiqué ci-dessus, chaque ligne comporte 31 variables. Une variable (la dernière variable du tableau ci-dessus) est appelée Class et représente la variable cible. Votre objectif sera d’entraîner un modèle qui utilise les autres variables pour prédire la valeur de la variable Class. Récupérons d’abord des statistiques de base sur la variable cible.\n",
    "\n",
    "Remarque : Pour des raisons de confidentialité, les noms originaux de la plupart des fonctionnalités sont anonymisés V1, V2. V28. Les valeurs de ces caractéristiques sont le résultat d’une transformation PCA et sont numériques. La fonctionnalité 'Class' est la variable cible et elle prend deux valeurs : 1 en cas de fraude et 0 dans le cas contraire. Pour plus d’informations sur l’ensemble de données, veuillez consulter cette page Web : https://www.kaggle.com/mlg-ulb/creditcardfraud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the set of distinct classes\n",
    "labels = big_raw_data.Class.unique()\n",
    "\n",
    "# get the count of each class\n",
    "sizes = big_raw_data.Class.value_counts().values\n",
    "\n",
    "# plot the class value counts\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%1.3f%%')\n",
    "ax.set_title('Target Variable Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the Class variable has two values: 0 (the credit card transaction is legitimate) and 1 (the credit card transaction is fraudulent). Thus, you need to model a binary classification problem. Moreover, the dataset is highly unbalanced, the target variable classes are not represented equally. This case requires special attention when training or when evaluating the quality of a model. One way of handing this case at train time is to bias the model to pay more attention to the samples in the minority class. The models under the current study will be configured to take into account the class weights of the samples at train/fit time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme indiqué ci-dessus, la variable Class a deux valeurs : 0 (la transaction par carte de crédit est légitime) et 1 (la transaction par carte de crédit est frauduleuse). Ainsi, vous devez modéliser un problème de classification binaire. De plus, le jeu de données est très déséquilibré, les classes de variables cibles ne sont pas représentées de manière égale. Ce cas nécessite une attention particulière lors de la formation ou lors de l’évaluation de la qualité d’un modèle. Une façon de traiter ce cas au moment du train est de biaiser le modèle pour accorder plus d’attention aux échantillons de la classe minoritaire. Les modèles faisant l’objet de l’étude actuelle seront configurés pour prendre en compte les poids de classe des échantillons au moment de l’entraînement et de l’ajustement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credit card transactions have different amounts. Could you plot a histogram that shows the distribution of these amounts? What is the range of these amounts (min/max)? Could you print the 90th percentile of the amount values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les transactions par carte de crédit ont des montants différents. Pourriez-vous tracer un histogramme qui montre la distribution de ces quantités ? Quelle est la fourchette de ces montants (min/max) ? Pourriez-vous imprimer le 90e centile des valeurs du montant ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum amount value is  0.0\n",
      "Maximum amount value is  25691.16\n",
      "90% of the transactions have an amount less or equal than  203.0\n"
     ]
    }
   ],
   "source": [
    "# we provide our solution here\n",
    "plt.hist(big_raw_data.Amount.values, 6, histtype='bar', facecolor='g')\n",
    "plt.show()\n",
    "\n",
    "print(\"Minimum amount value is \", np.min(big_raw_data.Amount.values))\n",
    "print(\"Maximum amount value is \", np.max(big_raw_data.Amount.values))\n",
    "print(\"90% of the transactions have an amount less or equal than \", np.percentile(raw_data.Amount.values, 90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salut Rodriguezmahi\n",
    "\n",
    "Merci pour votre message ! Nous serons heureux de vous aider.\n",
    "\n",
    "Décomposons cet exercice pratique étape par étape et expliquons à la fois le code et sa sortie :\n",
    "\n",
    "1. Tracé d'un histogramme des montants des transactions :\n",
    "\n",
    "plt.hist(big_raw_data.Amount.values, 6, histtype='bar', facecolor='g')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "· plt.hist() : Cette fonction génère un histogramme des données. Un histogramme est une représentation graphique qui organise un groupe de points de données en plages spécifiées par l'utilisateur (bins).\n",
    "\n",
    "big_raw_data.Amount(quantité).values : Cette fonction extrait les valeurs de la colonne Amount(quantité) du DataFrame big_raw_data, qui contient vraisemblablement les montants des transactions. La fonction .values les renvoie sous forme de tableau NumPy, ce qui la rend adaptée au traçage.\n",
    "\n",
    "6 : Ceci spécifie le nombre de compartiments (c'est-à-dire le nombre d'intervalles dans lesquels les données sont divisées). Dans ce cas, l'histogramme divisera les montants des transactions en 6 intervalles ou groupes.\n",
    "\n",
    "histtype='bar' : Spécifie le type d'histogramme. bar crée un histogramme standard avec des barres pour chaque compartiment.\n",
    "\n",
    "facecolor='g' : Définit la couleur des barres de l'histogramme sur vert ('g' signifie vert).\n",
    "\n",
    "· plt.show() : Cette ligne affiche l'histogramme.\n",
    "\n",
    "Explication de la sortie :\n",
    "\n",
    "Le résultat sera un histogramme montrant la distribution des montants de transaction dans l'ensemble de données. L'axe des x représentera les plages de montants de transaction (binets), tandis que l'axe des y représentera la fréquence (c'est-à-dire le nombre de transactions comprises dans chaque plage).\n",
    "\n",
    "Si la plupart des transactions comportent de petits montants, le côté gauche de l'histogramme (cases inférieures) comportera des barres plus hautes.\n",
    "\n",
    "S'il y a des transactions importantes, le côté droit aura moins de barres plus courtes.\n",
    "\n",
    "2. Impression des montants minimum et maximum des transactions :\n",
    "\n",
    "print(\"Minimum amount value is \", np.min(big_raw_data.Amount.values))\n",
    "\n",
    "print(\"Maximum amount value is \", np.max(big_raw_data.Amount.values))\n",
    "\n",
    "np.min() : Ceci calcule la valeur minimale de la colonne Montant(quantité) (c'est-à-dire le plus petit montant de transaction dans l'ensemble de données).\n",
    "\n",
    "np.max() : Ceci calcule la valeur maximale de la colonne Montant(quantité) (c'est-à-dire le montant de transaction le plus élevé dans l'ensemble de données).\n",
    "\n",
    "Explication de la sortie :\n",
    "\n",
    "La sortie affichera les montants de transaction les plus petits et les plus grands dans l'ensemble de données. Ces valeurs fournissent une compréhension de base de la plage des montants de transaction :\n",
    "\n",
    "Montant minimum : il peut s'agir d'une très petite valeur, telle que 0, ou d'une valeur faible comme 1 $ ou 5 $, indiquant la plus petite transaction effectuée.\n",
    "\n",
    "Montant maximal : il s’agit de la transaction la plus importante de l’ensemble de données, qui peut être beaucoup plus importante que la majorité des transactions.\n",
    "\n",
    "3. Recherche du 90e percentile des montants des transactions :\n",
    "\n",
    "print(\"90% of the transactions have an amount less or equal than \", np.percentile(big_raw_data.Amount.values, 90))\n",
    "np.percentile() : Cette fonction calcule le centile des données. Un centile est une valeur en dessous de laquelle se situe un certain pourcentage de données.\n",
    "\n",
    "90e percentile : cette ligne calcule la valeur en dessous de laquelle se situent 90 % des montants des transactions. En d'autres termes, 90 % de toutes les transactions ont un montant inférieur ou égal à cette valeur.\n",
    "\n",
    "Explication de la sortie :\n",
    "\n",
    "La sortie affichera le montant de la transaction qui correspond au 90e percentile .\n",
    "\n",
    "Par exemple, si le résultat indique « 90 % des transactions ont un montant inférieur ou égal à 500 $ », cela signifie que la plupart des transactions (90 %) sont de 500 $ ou moins, et que seulement 10 % des transactions dépassent 500 $.\n",
    "\n",
    "Cela vous donne une idée de la distribution des montants des transactions et permet d'identifier les valeurs aberrantes ou les transactions inhabituellement importantes qui se produisent rarement.\n",
    "\n",
    "Résumé de ce que fait le code :\n",
    "\n",
    "1. Histogramme : permet de visualiser la distribution des montants des transactions. La forme de l'histogramme vous aide à comprendre si les données sont biaisées, s'il existe de nombreuses transactions de petite ou de grande taille et comment les montants des transactions sont répartis dans l'ensemble de données.\n",
    "\n",
    "2. Minimum et maximum : le code calcule et imprime les montants de transaction les plus petits et les plus grands. Cela donne un aperçu de la plage de valeurs de transaction dans l'ensemble de données.\n",
    "\n",
    "3. 90e percentile : le code calcule le montant en dessous duquel se situent 90 % des transactions. Cela est utile pour identifier les montants de transaction typiques, avec seulement 10 % des transactions étant inhabituellement importantes ou aberrantes.\n",
    "\n",
    "Résultat : cela signifie que la plus petite transaction est de 0 $ (peut-être un service gratuit), la plus grande transaction est de 5 000 $ et 90 % des transactions sont de 300 $ ou moins. Seuls les 10 % les plus importantes dépassent 300 $.\n",
    "\n",
    "Bon apprentissage !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dataset_preprocessing\">\n",
    "    <h2>Dataset Preprocessing</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will prepare the data for training. \n",
    "\n",
    "Dans cette sous-section, vous préparerez les données pour la formation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape= (2848070, 29) y.shape= (2848070,)\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing such as scaling/normalization is typically useful for \n",
    "# linear models to accelerate the training convergence\n",
    "\n",
    "\n",
    "# Le prétraitement des données tel que la mise à l'échelle/normalisation est généralement utile pour les modèles linéaires afin d'accélérer la convergence de l'apprentissage. \n",
    "# les modèles linéaires pour accélérer la convergence de l'apprentissage\n",
    "\n",
    "\n",
    "# standardize features by removing the mean and scaling to unit variance\n",
    "# standardiser les caractéristiques en supprimant la moyenne et en mettant à l'échelle la variance unitaire\n",
    "\n",
    "\n",
    "big_raw_data.iloc[:, 1:30] = StandardScaler().fit_transform(big_raw_data.iloc[:, 1:30])\n",
    "\n",
    "data_matrix = big_raw_data.values\n",
    "\n",
    "# X: feature matrix (for this analysis, we exclude the Time variable from the dataset)\n",
    "# X : matrice des caractéristiques (pour cette analyse, nous excluons la variable Temps de l'ensemble des données)\n",
    "\n",
    "X = data_matrix[:, 1:30]\n",
    "\n",
    "# y: labels vector\n",
    "y = data_matrix[:, 30]\n",
    "\n",
    "# data normalization\n",
    "X = normalize(X, norm=\"l1\")\n",
    "\n",
    "# print the shape of the features matrix and the labels vector\n",
    "print('X.shape=', X.shape, 'y.shape=', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prétraitement des données : mise à l'échelle et normalisation\n",
    "\n",
    "Le commentaire dans le code mentionne que la mise à l'échelle/normalisation est utile pour les modèles linéaires afin d'accélérer la convergence de la formation. Cela s'applique aux modèles tels que la régression logistique , les machines à vecteurs de support (SVM) et autres, où la mise à l'échelle des données a un impact sur la capacité du modèle à apprendre efficacement.\n",
    "\n",
    "Pourquoi la mise à l’échelle et la normalisation ?\n",
    "\n",
    "- Mise à l'échelle : de nombreux algorithmes d'apprentissage automatique, en particulier ceux qui reposent sur une optimisation basée sur le gradient (comme les modèles linéaires, les SVM, les réseaux neuronaux, etc.), sont sensibles à l'échelle des données d'entrée. Les caractéristiques avec des valeurs plus élevées peuvent dominer le processus d'apprentissage, ce qui conduit à des modèles biaisés. La mise à l'échelle garantit que chaque caractéristique contribue de manière égale au processus de formation.\n",
    "\n",
    "- Normalisation : cette fonction permet de s'assurer que toutes les entités ont des plages (ou des magnitudes) comparables. Elle permet aux modèles qui s'appuient sur les distances entre les points (comme les modèles KNN, SVM ou linéaires) d'être plus performants, car de grandes différences dans les échelles des entités peuvent fausser ces distances.\n",
    "\n",
    "2. Normalisation à l'aide de StandardScaler :\n",
    "\n",
    "big_raw_data.iloc[:, 1:30] = StandardScaler().fit_transform(big_raw_data.iloc[:, 1:30])\n",
    "\n",
    "StandardScaler() : La standardisation met à l'échelle les données en supprimant la moyenne et en les mettant à l'échelle en fonction de la variance unitaire. Cela signifie que chaque fonction aura :\n",
    "\n",
    "Moyenne nulle : la moyenne des valeurs des caractéristiques est décalée vers 0.\n",
    "\n",
    "Variance unitaire : Les valeurs sont mises à l’échelle de sorte que l’écart type devienne 1.\n",
    "\n",
    "Pourquoi utiliser StandardScaler ?\n",
    "\n",
    "Cela garantit que les fonctionnalités sont sur une échelle commune, ce qui est important pour de nombreux algorithmes d'apprentissage automatique qui reposent sur des comparaisons de fonctionnalités ou une optimisation basée sur le gradient.\n",
    "\n",
    "Sans mise à l'échelle, les fonctionnalités avec des plages numériques plus grandes peuvent dominer celles avec des plages plus petites, ce qui entraîne de mauvaises performances du modèle.\n",
    "\n",
    "A quoi sert cette ligne :\n",
    "\n",
    "big_raw_data.iloc[:, 1:30]: Ceci sélectionne les colonnes 1 à 29 (en supposant que la première colonne soit exclue, éventuellement une fonctionnalité non numérique ou basée sur le temps).\n",
    "\n",
    "StandardScaler().fit_transform(...) : applique la standardisation sur les colonnes sélectionnées. Chaque colonne (fonctionnalité) est standardisée séparément.\n",
    "\n",
    "Le résultat est que les caractéristiques des colonnes 1 à 29 auront désormais une moyenne de 0 et un écart type de 1, ce qui les rend plus comparables.\n",
    "\n",
    "3. Extraction de la matrice de caractéristiques (X) et des étiquettes (y) :\n",
    "\n",
    "data_matrix = big_raw_data.values\n",
    "\n",
    "X = data_matrix[:, 1:30] \n",
    "\n",
    "y = data_matrix[:, 30]\n",
    "\n",
    "data_matrix = big_raw_data.values : Cela convertit le DataFrame big_raw_data en un tableau NumPy, permettant une indexation facile.\n",
    "\n",
    "Matrice de caractéristiques (X) :\n",
    "\n",
    "data_matrix[:, 1:30] : Cette fonction extrait les colonnes 1 à 29, qui sont les caractéristiques de l'ensemble de données. (La première colonne, probablement la colonne « Heure », est exclue car elle peut ne pas être pertinente pour cette analyse.)\n",
    "\n",
    "· Vecteur d'étiquettes (y) :\n",
    "\n",
    "data_matrix[:, 30] : Ceci extrait la 30e colonne, qui représente la variable cible (étiquettes), utilisée pour la formation du modèle.\n",
    "\n",
    "4. Normalisation des données :\n",
    "\n",
    "X = normaliser(X, norm=\"l1\")\n",
    "\n",
    "Normalisation : Dans cette étape, la matrice de caractéristiques (X) est normalisée. La fonction de normalisation transforme les valeurs des caractéristiques de manière à ce que la norme de chaque échantillon soit égale à 1 (ou à toute autre valeur spécifiée).\n",
    "\n",
    "Normalisation L1 (norm=\"l1\") : Chaque échantillon (ligne dans X) est mis à l'échelle de sorte que la somme des valeurs absolues des caractéristiques soit égale à 1. Cela signifie que la grandeur absolue des valeurs des caractéristiques est préservée, mais elles sont rééchelonnées à une somme fixe.\n",
    "\n",
    "Pourquoi utiliser la normalisation L1 ? Elle est utile lorsque les entités ont des échelles différentes et que vous souhaitez les amener à une échelle comparable, en particulier lorsque vous vous souciez des proportions relatives des entités plutôt que de leurs valeurs absolues. Elle est utile dans les modèles sensibles à l'ampleur des valeurs des entités, tels que les SVM ou les classificateurs linéaires.\n",
    "\n",
    "5. Impression de la forme des entités et des étiquettes :\n",
    "\n",
    "print('X.forme=', X.forme, 'y.forme=', y.forme)\n",
    "\n",
    "X.shape : imprime les dimensions de la matrice de fonctionnalités X. Cela vous indique le nombre d'échantillons (lignes) et de fonctionnalités (colonnes) présents dans l'ensemble de données après le prétraitement.\n",
    "\n",
    "Y.shape : imprime la forme du vecteur d'étiquettes y, qui vous indique le nombre d'échantillons présents dans l'ensemble de données.\n",
    "\n",
    "Bon apprentissage !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dataset_split\">\n",
    "    <h2>Dataset Train/Test Split</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is ready for building the classification models, you need to first divide the pre-processed dataset into a subset to be used for training the model (the train set) and a subset to be used for evaluating the quality of the model (the test set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que l'ensemble de données est prêt pour la construction des modèles de classification, vous devez d'abord diviser l'ensemble de données prétraitées en un sous-ensemble à utiliser pour l'entraînement du modèle (l'ensemble d'entraînement) et un sous-ensemble à utiliser pour l'évaluation de la qualité du modèle (l'ensemble de test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= (1993649, 29) Y_train.shape= (1993649,)\n",
      "X_test.shape= (854421, 29) Y_test.shape= (854421,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)       \n",
    "print('X_train.shape=', X_train.shape, 'Y_train.shape=', y_train.shape)\n",
    "print('X_test.shape=', X_test.shape, 'Y_test.shape=', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salut Rodriguezmahi\n",
    "\n",
    "Merci pour votre message ! Nous serons heureux de vous aider.\n",
    "\n",
    "Le paramètre stratify=y de la fonction train_test_split garantit que la proportion de classes dans la variable cible y est préservée lors de la division des données en ensembles d'apprentissage et de test. Voici une explication détaillée :\n",
    "\n",
    "Objectif du paramètre stratify=y :\n",
    "\n",
    "Lorsque vous divisez les données en ensembles d'entraînement et de test, en particulier dans les tâches de classification, vous devez vous assurer que la distribution des classes dans les deux ensembles reflète la distribution de l'ensemble de données d'origine. Cela est particulièrement important si vous disposez d'un ensemble de données déséquilibré, dans lequel une classe est considérablement sous-représentée par rapport aux autres.\n",
    "\n",
    "· Sans stratify=y : les ensembles d'entraînement et de test peuvent se retrouver avec des proportions de classes différentes, notamment en cas de déséquilibre des classes. Cela peut conduire à des modèles biaisés qui fonctionnent mal sur la classe minoritaire, car l'ensemble de test peut ne pas représenter la distribution réelle des données.\n",
    "\n",
    "· Avec stratify=y : Le paramètre stratify=y garantit que la division conserve la même distribution de classes que l'ensemble de données d'origine y. Cela garantit que les ensembles d'entraînement et de test ont le même ratio de chaque classe que dans l'ensemble de données d'origine, ce qui est essentiel pour entraîner et évaluer de manière équitable les modèles de classification.\n",
    "\n",
    "Comment ça marche :\n",
    "\n",
    "X_train, X_test, y_train, y_test : Ces variables stockent les fonctionnalités et les étiquettes des ensembles d'entraînement et de test après la division.\n",
    "\n",
    "test_size=0.3 : Cela signifie que 30 % des données seront utilisées pour l'ensemble de test, tandis que 70 % seront utilisées pour l'ensemble d'entraînement.\n",
    "\n",
    "random_state=42 : Cela garantit que la division est reproductible, ce qui signifie que vous obtiendrez les mêmes ensembles d'entraînement et de test à chaque fois que vous exécuterez le code.\n",
    "\n",
    "Exemple:\n",
    "\n",
    "Disons que votre variable cible y présente un déséquilibre de classe comme celui-ci :\n",
    "\n",
    "Classe 0 : 90% des données\n",
    "\n",
    "Classe 1 : 10 % des données\n",
    "\n",
    "Si vous utilisez stratify=y, la division conservera ce ratio dans les ensembles d'entraînement et de test. Par exemple :\n",
    "\n",
    "Ensemble d'entraînement (70 % des données) : 90 % Classe 0, 10 % Classe 1\n",
    "\n",
    "Ensemble de test (30 % des données) : 90 % Classe 0, 10 % Classe 1\n",
    "\n",
    "Sans stratify=y, la distribution des classes dans les ensembles d'entraînement et de test pourrait être biaisée, un ensemble pouvant contenir un nombre disproportionné d'échantillons d'une classe par rapport à l'autre, ce qui conduirait à une évaluation inexacte du modèle.\n",
    "\n",
    "Pourquoi utiliser stratify=y ?\n",
    "\n",
    "Éviter le déséquilibre des classes dans les fractionnements : garantit que les ensembles d'entraînement et de test reflètent la distribution de classe d'origine, ce qui est particulièrement important pour les ensembles de données déséquilibrés.\n",
    "\n",
    "Formation améliorée du modèle : aide le modèle à mieux apprendre à partir des données de formation, car il voit une proportion équilibrée de chaque classe.\n",
    "\n",
    "Évaluation équitable : garantit que l’ensemble de tests est une bonne représentation des données d’origine, offrant ainsi une évaluation des performances plus fiable.\n",
    "\n",
    "Résumé:\n",
    "\n",
    "Le paramètre stratify=y est utilisé pour préserver la distribution de classe de la variable cible lors de la division de l'ensemble de données. Il garantit que les ensembles d'apprentissage et de test ont des proportions similaires de chaque classe que l'ensemble de données d'origine, ce qui est particulièrement utile lors du traitement de données déséquilibrées.\n",
    "\n",
    "Bon apprentissage !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dt_sklearn\">\n",
    "    <h2>Build a Decision Tree Classifier model with Scikit-Learn</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scikit-Learn] Training time (s):  48.98344\n"
     ]
    }
   ],
   "source": [
    "# compute the sample weights to be used as input to the train routine so that \n",
    "# it takes into account the class imbalance present in this dataset\n",
    "\n",
    "# calculer les poids de l'échantillon à utiliser comme entrée de la routine de formation de manière à ce que \n",
    "# qu'il prenne en compte le déséquilibre des classes présent dans cet ensemble de données\n",
    "\n",
    "w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "# import the Decision Tree Classifier Model from scikit-learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "# pour que le résultat soit reproductible lors de plusieurs appels de fonctions, fixer random_state à une valeur entière donnée\n",
    "\n",
    "sklearn_dt = DecisionTreeClassifier(max_depth=4, random_state=35)\n",
    "\n",
    "# train a Decision Tree Classifier using scikit-learn\n",
    "# former un arbre de décision en utilisant scikit-learn\n",
    "\n",
    "t0 = time.time()\n",
    "sklearn_dt.fit(X_train, y_train, sample_weight=w_train)\n",
    "sklearn_time = time.time()-t0\n",
    "print(\"[Scikit-Learn] Training time (s):  {0:.5f}\".format(sklearn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salut Rodriguezmahi\n",
    "\n",
    "Merci pour votre message ! Nous serons heureux de vous aider.\n",
    "\n",
    "Voici une explication détaillée du code :\n",
    "\n",
    "1. Gestion du déséquilibre des classes :\n",
    "\n",
    "w_train = compute_sample_weight('équilibré', y_train)\n",
    "\n",
    "Déséquilibre des classes : dans de nombreux ensembles de données, une classe (par exemple, les transactions frauduleuses) peut être sous-représentée par rapport à une autre (par exemple, les transactions non frauduleuses). C'est ce qu'on appelle un déséquilibre des classes .\n",
    "\n",
    "compute_sample_weight('balanced', y_train) : Cette fonction calcule les poids d'échantillon pour tenir compte du déséquilibre de classe dans les données d'apprentissage (y_train). Le mode « balanced » ajuste automatiquement le poids inversement proportionnel aux fréquences de classe, en donnant des poids plus élevés à la classe minoritaire.\n",
    "\n",
    "Par exemple, si la classe A apparaît moins fréquemment que la classe B, l’algorithme attribuera un poids plus élevé aux échantillons de classe A pour rendre leur impact sur le processus de prise de décision comparable à celui des échantillons de classe B.\n",
    "\n",
    "Ces poids d'échantillon seront utilisés lors de la formation pour garantir que le classificateur accorde une attention égale aux deux classes.\n",
    "\n",
    "2. Importation du classificateur d'arbre de décision :\n",
    "\n",
    "à partir de sklearn.tree importer DecisionTreeClassifier\n",
    "\n",
    "DecisionTreeClassifier : cela importe le classificateur d'arbre de décision de Scikit-Learn, qui est un type d'algorithme d'apprentissage supervisé utilisé pour les tâches de classification. Les arbres de décision créent un modèle qui prédit la classe d'une variable cible en fonction des fonctionnalités d'entrée en divisant les données de manière récursive.\n",
    "\n",
    "3. Initialisation du classificateur :\n",
    "\n",
    "sklearn_dt = DecisionTreeClassifier(profondeur_max=4, état_aléatoire=35)\n",
    "\n",
    "max_depth=4 : limite la profondeur de l'arbre de décision à 4 niveaux. La limitation de la profondeur permet d'éviter le surajustement, qui se produit lorsque le modèle apprend trop de détails à partir des données d'entraînement, ce qui entraîne une mauvaise généralisation à de nouvelles données invisibles.\n",
    "\n",
    "random_state=35 : cette valeur est définie pour garantir la reproductibilité. En corrigeant random_state, le processus de formation produira le même résultat à chaque exécution du code, car les décisions aléatoires prises lors de la création de l'arborescence (comme la gestion des divisions de données) resteront cohérentes.\n",
    "\n",
    "4. Entraînement du classificateur d’arbre de décision :\n",
    "\n",
    "t0 = time.time() sklearn_dt.fit(X_train, y_train, sample_weight=w_train) sklearn_time = time.time()-t0\n",
    "time.time() : Cette fonction renvoie l'heure actuelle en secondes depuis l'époque (un moment précis, généralement le 1er janvier 1970). Elle est souvent utilisée pour mesurer des intervalles de temps.\n",
    "\n",
    "t0 = time.time() : Capture le temps juste avant le début de la formation.\n",
    "\n",
    "sklearn_dt.fit(X_train, y_train, sample_weight=w_train) : Cette ligne entraîne le classificateur d'arbre de décision à l'aide des données d'apprentissage (X_train, y_train) et des poids d'échantillon calculés (w_train).\n",
    "\n",
    "X_train : les fonctionnalités d’entrée pour les données d’entraînement.\n",
    "\n",
    "y_train : les étiquettes cibles (classe) pour les données d'entraînement.\n",
    "\n",
    "sample_weight=w_train : garantit que le processus de formation prend en compte le déséquilibre des classes en attribuant des poids plus élevés aux échantillons de classes minoritaires.\n",
    "\n",
    "time.time()-t0 : mesure la durée du processus de formation. Il calcule le temps écoulé en soustrayant l'heure de début (t0) de l'heure actuelle à laquelle la formation se termine. Cela vous donne le temps total nécessaire à la formation du modèle en secondes.\n",
    "\n",
    "5. Affichez le temps de formation :\n",
    "\n",
    "print(\"[Scikit-Learn] Training time (s): {0:.5f}\".format(sklearn_time))\n",
    "\n",
    "\n",
    "Affichage du temps de formation : cette option affiche le temps de formation de l'arbre de décision Scikit-Learn, formaté à cinq décimales (pour une plus grande précision). Le temps de formation indique le temps qu'il a fallu au classificateur d'arbre de décision pour apprendre à partir des données.\n",
    "\n",
    "Résumé des étapes clés :\n",
    "\n",
    "Gestion du déséquilibre des classes : compute_sample_weight calcule les poids pour garantir que les classes majoritaires et minoritaires sont correctement prises en compte pendant la formation.\n",
    "\n",
    "Configuration de l'arbre de décision : le DecisionTreeClassifier est initialisé avec un max_depth pour éviter le surajustement et un random_state pour la reproductibilité.\n",
    "\n",
    "Processus de formation : le classificateur est formé à l'aide des données de formation pondérées et le temps de formation est mesuré à l'aide de la différence entre l'heure de début et l'heure de fin (time.time()).\n",
    "\n",
    "Pourquoi la soustraction time.time()-t0 ?\n",
    "\n",
    "Cette soustraction permet de calculer la différence de temps entre le début et la fin du processus de formation. En procédant ainsi, vous pouvez suivre le temps nécessaire à la formation du modèle, ce qui est utile pour comparer différents modèles ou optimiser pour une formation plus rapide.\n",
    "\n",
    "Bon apprentissage !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dt_snapml\">\n",
    "    <h2>Build a Decision Tree Classifier model with Snap ML</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Training time (s):  10.68923\n"
     ]
    }
   ],
   "source": [
    "# if not already computed, \n",
    "# compute the sample weights to be used as input to the train routine so that \n",
    "# it takes into account the class imbalance present in this dataset\n",
    "# w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "\n",
    "# s'il n'a pas déjà été calculé, \n",
    "# calculer les poids de l'échantillon à utiliser en entrée de la routine de formation de façon à ce que \n",
    "# il prenne en compte le déséquilibre des classes présent dans cet ensemble de données\n",
    "# w_train = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "\n",
    "# import the Decision Tree Classifier Model from Snap ML\n",
    "from snapml import DecisionTreeClassifier\n",
    "\n",
    "# Snap ML offers multi-threaded CPU/GPU training of decision trees, unlike scikit-learn\n",
    "# to use the GPU, set the use_gpu parameter to True\n",
    "# snapml_dt = DecisionTreeClassifier(max_depth=4, random_state=45, use_gpu=True)\n",
    "\n",
    "# to set the number of CPU threads used at training time, set the n_jobs parameter\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Snap ML offre un apprentissage multithread CPU/GPU des arbres de décision, contrairement à scikit-learn\n",
    "# pour utiliser le GPU, mettre le paramètre use_gpu à True\n",
    "# snapml_dt = DecisionTreeClassifier(max_depth=4, random_state=45, use_gpu=True)\n",
    "\n",
    "# pour définir le nombre de threads CPU utilisés au moment de l'apprentissage, définissez le paramètre n_jobs\n",
    "# pour que les résultats soient reproductibles sur plusieurs appels de fonction, fixer random_state à une valeur entière donnée\n",
    "snapml_dt = DecisionTreeClassifier(max_depth=4, random_state=45, n_jobs=4)\n",
    "\n",
    "# train a Decision Tree Classifier model using Snap ML\n",
    "t0 = time.time()\n",
    "snapml_dt.fit(X_train, y_train, sample_weight=w_train)\n",
    "snapml_time = time.time()-t0\n",
    "print(\"[Snap ML] Training time (s):  {0:.5f}\".format(snapml_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dt_sklearn_snapml\">\n",
    "    <h2>Evaluate the Scikit-Learn and Snap ML Decision Tree Classifier Models</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dt_sklearn_snapml\">\n",
    "    <h2>Évaluer les modèles de classificateur d’arbre de décision Scikit-Learn et Snap ML</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : 4.58x \n",
      "[Scikit-Learn] ROC-AUC score : 0.966\n",
      "[Snap ML] ROC-AUC score : 0.966\n"
     ]
    }
   ],
   "source": [
    "# Snap ML vs Scikit-Learn training speedup\n",
    "# Snap ML vs Scikit-Learn : accélération de l'entraînement\n",
    "training_speedup = sklearn_time/snapml_time\n",
    "print('[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : {0:.2f}x '.format(training_speedup))\n",
    "# run inference and compute the probabilities of the test samples \n",
    "# to belong to the class of fraudulent transactions\n",
    "\n",
    "# Lancer l'inférence et calculer les probabilités que les échantillons testés appartiennent à la classe des transactions frauduleuses \n",
    "# d'appartenir à la classe des transactions frauduleuses\n",
    "sklearn_pred = sklearn_dt.predict_proba(X_test)[:,1]\n",
    "# evaluate the Compute Area Under the Receiver Operating Characteristic \n",
    "# Curve (ROC-AUC) score from the predictions\n",
    "\n",
    "# évaluer l'aire sous la courbe de la caractéristique d'exploitation du récepteur (ROC-AUC) des prédictions. \n",
    "# (ROC-AUC) des prédictions.\n",
    "sklearn_roc_auc = roc_auc_score(y_test, sklearn_pred)\n",
    "print('[Scikit-Learn] ROC-AUC score : {0:.3f}'.format(sklearn_roc_auc))\n",
    "# run inference and compute the probabilities of the test samples\n",
    "# to belong to the class of fraudulent transactions\n",
    "# Lancer l'inférence et calculer les probabilités que les échantillons testés appartiennent à la classe des transactions frauduleuses\n",
    "# d'appartenir à la classe des transactions frauduleuses\n",
    "snapml_pred = snapml_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "# evaluate the Compute Area Under the Receiver Operating Characteristic\n",
    "# Curve (ROC-AUC) score from the prediction scores\n",
    "\n",
    "# évaluer l'aire sous la courbe de la caractéristique d'exploitation du récepteur (ROC-AUC) à partir des scores de prédiction.\n",
    "# (ROC-AUC) à partir des scores de prédiction\n",
    "snapml_roc_auc = roc_auc_score(y_test, snapml_pred)   \n",
    "print('[Snap ML] ROC-AUC score : {0:.3f}'.format(snapml_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salut Rodriguezmahi\n",
    "\n",
    "Merci pour votre message ! Nous serons heureux de vous aider.\n",
    "\n",
    "Le code compare la vitesse d'apprentissage et les performances (score ROC-AUC) des classificateurs d'arbres de décision à l'aide de deux bibliothèques différentes : Snap ML et Scikit-Learn . Voici une description détaillée de ce que fait le code :\n",
    "\n",
    "1. Calcul de l'accélération de l'entraînement :\n",
    "\n",
    "training_speedup = sklearn_time / snapml_time\n",
    "print('[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : {0:.2f}x '.format(training_speedup))\n",
    "\n",
    "sklearn_time et snapml_time représentent le temps nécessaire pour former un modèle d'arbre de décision à l'aide de Scikit-Learn et Snap ML, respectivement.\n",
    "\n",
    "Calcul de l'accélération : training_speedup est le rapport entre le temps d'entraînement de Scikit-Learn et le temps d'entraînement de Snap ML. Si Snap ML est plus rapide, le rapport sera supérieur à 1.\n",
    "\n",
    "Résultat de sortie : Le résultat montre combien de fois Snap ML est plus rapide par rapport à Scikit-Learn, formaté à deux décimales.\n",
    "\n",
    "2. Inférence et prédiction pour Scikit-Learn :\n",
    "\n",
    "sklearn_pred = sklearn_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "predict_proba(X_test) : Cette méthode est utilisée pour calculer les estimations de probabilité pour les échantillons de test (X_test). Elle renvoie la probabilité de chaque classe (par exemple, les transactions frauduleuses et non frauduleuses). L'index [1] est utilisé pour extraire les probabilités que les échantillons de test appartiennent à la classe frauduleuse.\n",
    "\n",
    "sklearn_roc_auc = roc_auc_score(y_test, sklearn_pred)\n",
    "print('[Scikit-Learn] ROC-AUC score : {0:.3f}'.format(sklearn_roc_auc))\n",
    "\n",
    "Calcul ROC-AUC : Le score ROC-AUC (Receiver Operating Characteristic - Area Under Curve) mesure la capacité du modèle à faire la distinction entre les classes positives (frauduleuses) et négatives (non frauduleuses). Un score plus proche de 1,0 indique une excellente classification de performance.\n",
    "\n",
    "Sortie : Le score ROC-AUC de Scikit-Learn est imprimé, formaté à trois décimales.\n",
    "\n",
    "[Scikit-Learn] ROC-AUC score : 0.966\n",
    "\n",
    "3. Inférence et prédiction pour Snap ML :\n",
    "\n",
    "snapml_pred = snapml_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "Semblable à la partie Scikit-Learn, Snap ML calcule la probabilité que chaque échantillon de test appartienne à la classe frauduleuse.\n",
    "\n",
    "snapml_roc_auc = roc_auc_score(y_test, snapml_pred)\n",
    "print('[Snap ML] ROC-AUC score : {0:.3f}'.format(snapml_roc_auc))\n",
    "\n",
    "Calcul ROC-AUC : Le score ROC-AUC pour Snap ML est calculé de la même manière que pour Scikit-Learn.\n",
    "\n",
    "Sortie : Le score Snap ML ROC-AUC est imprimé, également formaté à trois décimales.\n",
    "\n",
    "Résultat:\n",
    "\n",
    "[Decision Tree Classifier] Snap ML vs. Scikit-Learn speedup : 4.53x [Scikit-Learn] ROC-AUC score : 0.966 [Snap ML] ROC-AUC score : 0.966\n",
    "Accélération : le modèle Snap ML est 4,53 fois plus rapide que le modèle Scikit-Learn en termes de temps de formation. Cela démontre une amélioration significative de la vitesse lors de l'utilisation de Snap ML pour la formation d'un classificateur d'arbre de décision.\n",
    "\n",
    "Scores ROC-AUC : Snap ML et Scikit-Learn produisent tous deux le même score ROC-AUC de 0,966 , ce qui indique que les deux modèles ont les mêmes performances de classification. Le score est très élevé, ce qui montre que les deux modèles sont performants pour distinguer les fraudes des transactions non frauduleuses.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Snap ML offre une accélération substantielle (4,53 fois plus rapide) de la formation tout en maintenant le même niveau de performance prédictive (score ROC-AUC) que Scikit-Learn .\n",
    "\n",
    "Cela fait de Snap ML un choix attrayant lorsque la vitesse de formation est importante, en particulier pour les grands ensembles de données, tout en garantissant des prédictions de haute qualité.\n",
    "\n",
    "J'espère que cela aide !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above both decision tree models provide the same score on the test dataset. However Snap ML runs the training routine faster than Scikit-Learn. This is one of the advantages of using Snap ML: acceleration of training of classical machine learning models, such as linear and tree-based models. For more Snap ML examples, please visit [snapml-examples](https://ibm.biz/BdPfxP).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme indiqué ci-dessus, les deux modèles d'arbre de décision fournissent le même score sur l'ensemble de données de test. Cependant, Snap ML exécute la routine d'apprentissage plus rapidement que Scikit-Learn. C'est l'un des avantages de l'utilisation de Snap ML : l'accélération de l'apprentissage des modèles classiques d'apprentissage automatique, tels que les modèles linéaires et les modèles à base d'arbres. Pour plus d'exemples de Snap ML, veuillez visiter [snapml-examples](https://ibm.biz/BdPfxP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_sklearn\">\n",
    "    <h2>Build a Support Vector Machine model with Scikit-Learn</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_sklearn\">\n",
    "    <h2>Construire un modèle de machine à vecteurs de support avec Scikit-Learn</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scikit-Learn] Training time (s):  95.63\n"
     ]
    }
   ],
   "source": [
    "# import the linear Support Vector Machine (SVM) model from Scikit-Learn\n",
    "# importation du modèle linéaire de machine à vecteurs de support (SVM) de Scikit-Learn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# instatiate a scikit-learn SVM model\n",
    "# to indicate the class imbalance at fit time, set class_weight='balanced'\n",
    "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
    "\n",
    "# instaurez un modèle SVM scikit-learn\n",
    "# pour indiquer le déséquilibre des classes au moment de l'ajustement, définir class_weight='balanced'\n",
    "# pour que la sortie soit reproductible à travers plusieurs appels de fonction, fixer random_state à une valeur entière donnée\n",
    "sklearn_svm = LinearSVC(class_weight='balanced', random_state=31, loss=\"hinge\", fit_intercept=False)\n",
    "\n",
    "# train a linear Support Vector Machine model using Scikit-Learn\n",
    "# former un modèle linéaire de machine à vecteur de support à l'aide de Scikit-Learn\n",
    "\n",
    "t0 = time.time()\n",
    "sklearn_svm.fit(X_train, y_train)\n",
    "sklearn_time = time.time() - t0\n",
    "print(\"[Scikit-Learn] Training time (s):  {0:.2f}\".format(sklearn_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_snap\">\n",
    "    <h2>Build a Support Vector Machine model with Snap ML</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_snap\">\n",
    "    <h2>Construire un modèle de machine à vecteurs de support avec Snap ML</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Training time (s):  47.87\n"
     ]
    }
   ],
   "source": [
    "# import the Support Vector Machine model (SVM) from Snap ML\n",
    "# importer le modèle de machine à vecteurs de support (SVM) à partir de Snap ML\n",
    "\n",
    "from snapml import SupportVectorMachine\n",
    "\n",
    "# in contrast to scikit-learn's LinearSVC, Snap ML offers multi-threaded CPU/GPU training of SVMs\n",
    "# to use the GPU, set the use_gpu parameter to True\n",
    "# snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, use_gpu=True, fit_intercept=False)\n",
    "\n",
    "\n",
    "# contrairement au LinearSVC de scikit-learn, Snap ML offre un entraînement CPU/GPU multithread des SVM\n",
    "# pour utiliser le GPU, définissez le paramètre use_gpu sur True\n",
    "# snapml_svm = SupportVectorMachine(class_weight='équilibré', random_state=25, use_gpu=Vrai, fit_intercept=Faux)\n",
    "\n",
    "# to set the number of threads used at training time, one needs to set the n_jobs parameter\n",
    "# Pour définir le nombre de threads utilisés au moment de l’entraînement, il faut définir le paramètre n_jobs\n",
    "snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, n_jobs=4, fit_intercept=False)\n",
    "# print(snapml_svm.get_params())\n",
    "\n",
    "# train an SVM model using Snap ML\n",
    "t0 = time.time()\n",
    "model = snapml_svm.fit(X_train, y_train)\n",
    "snapml_time = time.time() - t0\n",
    "print(\"[Snap ML] Training time (s):  {0:.2f}\".format(snapml_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_sklearn_snap\">\n",
    "    <h2>Evaluate the Scikit-Learn and Snap ML Support Vector Machine Models</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_sklearn_snap\">\n",
    "    <h2>Évaluer les modèles de machines vectorielles de support Scikit-Learn et Snap ML</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Support Vector Machine] Snap ML vs. Scikit-Learn training speedup : 2.00x \n",
      "[Scikit-Learn] ROC-AUC score:   0.984\n",
      "[Snap ML] ROC-AUC score:   0.985\n"
     ]
    }
   ],
   "source": [
    "# compute the Snap ML vs Scikit-Learn training speedup\n",
    "# calculer l’accélération de la formation Snap ML vs Scikit-Learn\n",
    "training_speedup = sklearn_time/snapml_time\n",
    "print('[Support Vector Machine] Snap ML vs. Scikit-Learn training speedup : {0:.2f}x '.format(training_speedup))\n",
    "\n",
    "# run inference using the Scikit-Learn model\n",
    "# get the confidence scores for the test samples\n",
    "\n",
    "# exécuter l’inférence à l’aide du modèle Scikit-Learn\n",
    "# Obtenir les scores de confiance pour les échantillons de test\n",
    "sklearn_pred = sklearn_svm.decision_function(X_test)\n",
    "\n",
    "# evaluate accuracy on test set\n",
    "# évaluer la précision sur l'ensemble de test\n",
    "acc_sklearn  = roc_auc_score(y_test, sklearn_pred)\n",
    "print(\"[Scikit-Learn] ROC-AUC score:   {0:.3f}\".format(acc_sklearn))\n",
    "\n",
    "# run inference using the Snap ML model\n",
    "# get the confidence scores for the test samples\n",
    "\n",
    "# exécuter l'inférence à l'aide du modèle ML de Snap\n",
    "# obtenir les scores de confiance pour les échantillons de test\n",
    "snapml_pred = snapml_svm.decision_function(X_test)\n",
    "\n",
    "# evaluate accuracy on test set\n",
    "acc_snapml  = roc_auc_score(y_test, snapml_pred)\n",
    "print(\"[Snap ML] ROC-AUC score:   {0:.3f}\".format(acc_snapml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above both SVM models provide the same score on the test dataset. However, as in the case of decision trees, Snap ML runs the training routine faster than Scikit-Learn. For more Snap ML examples, please visit [snapml-examples](https://ibm.biz/BdPfxP). Moreover, as shown above, not only is Snap ML seemlessly accelerating scikit-learn applications, but the library's Python API is also compatible with scikit-learn metrics and data preprocessors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme indiqué ci-dessus, les deux modèles SVM fournissent le même score sur l'ensemble de données de test. Cependant, comme dans le cas des arbres de décision, Snap ML exécute la routine d'apprentissage plus rapidement que Scikit-Learn. Pour plus d'exemples de Snap ML, veuillez visiter [snapml-examples](https://ibm.biz/BdPfxP). De plus, comme indiqué ci-dessus, non seulement Snap ML accélère sans problème les applications scikit-learn, mais l'API Python de la bibliothèque est également compatible avec les métriques scikit-learn et les préprocesseurs de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will evaluate the quality of the SVM models trained above using the hinge loss metric (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html). Run inference on the test set using both Scikit-Learn and Snap ML models. Compute the hinge loss metric for both sets of predictions. Print the hinge losses of Scikit-Learn and Snap ML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, vous allez évaluer la qualité des modèles SVM entraînés ci-dessus à l’aide de la métrique de perte de charnière (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html). Exécutez l’inférence sur l’ensemble de test à l’aide des modèles Scikit-Learn et Snap ML. Calculez la métrique de perte de charnière pour les deux ensembles de prédictions. Imprimez les pertes de charnière de Scikit-Learn et Snap ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Snap ML] Hinge loss:   0.228\n",
      "[Scikit-Learn] Hinge loss:   0.228\n"
     ]
    }
   ],
   "source": [
    "# get the confidence scores for the test samples\n",
    "# Obtenir les scores de confiance pour les échantillons testés\n",
    "\n",
    "sklearn_pred = sklearn_svm.decision_function(X_test)\n",
    "snapml_pred  = snapml_svm.decision_function(X_test)\n",
    "\n",
    "# import the hinge_loss metric from scikit-learn\n",
    "# Importer la métrique hinge_loss depuis scikit-learn\n",
    "\n",
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "# evaluate the hinge loss from the predictions\n",
    "# évaluer la perte de la charnière à partir des prévisions\n",
    "\n",
    "loss_snapml = hinge_loss(y_test, snapml_pred)\n",
    "print(\"[Snap ML] Hinge loss:   {0:.3f}\".format(loss_snapml))\n",
    "\n",
    "# evaluate the hinge loss metric from the predictions\n",
    "# évaluer la perte de la charnière à partir des prévisions\n",
    "loss_sklearn = hinge_loss(y_test, sklearn_pred)\n",
    "print(\"[Scikit-Learn] Hinge loss:   {0:.3f}\".format(loss_snapml))\n",
    "\n",
    "# the two models should give the same Hinge loss\n",
    "# les deux modèles doivent donner la même perte de charnière\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salut Rodriguezmahi\n",
    "\n",
    "Merci pour votre message ! Nous serons heureux de vous aider.\n",
    "\n",
    "La perte de charnière est principalement utilisée dans l'apprentissage automatique pour les modèles de classification à « marge maximale », en particulier les machines à vecteurs de support (SVM). Elle mesure l'erreur de classification, en particulier pour les classificateurs basés sur les marges. En termes plus simples :\n",
    "\n",
    "Si la classe prédite et la classe réelle correspondent et se situent au-delà de la limite de décision (c'est-à-dire que la marge correcte est maintenue), la perte est nulle.\n",
    "\n",
    "Si la prédiction est incorrecte ou dans la marge, la perte de charnière est positive et pénalise le modèle.\n",
    "\n",
    "La perte de charnière est calculée comme suit :\n",
    "\n",
    "où:\n",
    "\n",
    "yyy est le vrai label (+1 ou -1),\n",
    "\n",
    "f(x)f(x)f(x) est la prédiction du modèle (le score de confiance ou la sortie de la fonction de décision).\n",
    "\n",
    "Si le produit de yyy et f(x)f(x)f(x) est supérieur ou égal à 1, la prédiction est correcte et se situe dans la marge acceptable. Dans le cas contraire, la perte augmente.\n",
    "\n",
    "Explication du Code :\n",
    "\n",
    "Prédictions du modèle : sklearn_pred = sklearn_svm.decision_function(X_test)\n",
    "\n",
    "snapml_pred = snapml_svm.decision_function(X_test)\n",
    "\n",
    "Ici, deux modèles SVM différents sont utilisés : l'un formé à l'aide de Scikit-Learn (sklearn_svm) et l'autre à l'aide de Snap ML (snapml_svm). La méthode decision_function(X_test) fournit les scores de confiance (ou valeurs de décision) pour chaque échantillon de test dans X_test. Ces scores indiquent à quelle distance un échantillon se trouve de la limite de décision (les valeurs positives signifiant une classe et les valeurs négatives l'autre classe).\n",
    "\n",
    "Importation de la mesure de perte de charnière : à partir de sklearn.metrics import hinge_loss\n",
    "\n",
    "La fonction hinge_loss de Scikit-Learn est importée pour calculer la perte de charnière pour les prédictions des deux modèles.\n",
    "\n",
    "Calcul de la perte de charnière pour le modèle Snap ML : loss_snapml = hinge_loss(y_test, snapml_pred)\n",
    "\n",
    "print(\"[Snap ML] Perte de charnière : {0:.3f}\".format(loss_snapml))\n",
    "\n",
    "hinge_loss(y_test, snapml_pred) calcule la perte de charnière pour les prédictions du SVM Snap ML (snapml_pred).\n",
    "\n",
    "Les étiquettes réelles (y_test) sont comparées aux prédictions pour calculer à quelle distance les valeurs prédites se trouvent de la marge correcte, ce qui entraîne une valeur de perte de charnière.\n",
    "\n",
    "Le résultat est imprimé, formaté à 3 décimales.\n",
    "\n",
    "Calcul de la perte de charnière pour le modèle Scikit-Learn : loss_sklearn = hinge_loss(y_test, sklearn_pred)\n",
    "\n",
    "print(\"[Scikit-Learn] Perte de charnière : {0:.3f}\".format(loss_sklearn))\n",
    "\n",
    "De même, hinge_loss(y_test, sklearn_pred) calcule la perte de charnière pour les prédictions du SVM Scikit-Learn.\n",
    "\n",
    "Le résultat est également imprimé, formaté à 3 décimales.\n",
    "\n",
    "Interprétation des résultats :\n",
    "\n",
    "Ce commentaire suggère que les modèles Snap ML SVM et Scikit-Learn SVM devraient tous deux donner la même perte de charnière, en supposant qu'ils ont été formés de manière similaire et que la fonction de décision se comporte de la même manière.\n",
    "\n",
    "Les valeurs de perte de charnière vous indiquent les performances de chaque modèle :\n",
    "\n",
    "Perte de charnière inférieure : signifie que davantage d'échantillons sont classés correctement avec la marge correcte, indiquant de meilleures performances.\n",
    "\n",
    "Perte de charnière plus élevée : signifie que davantage d'échantillons sont mal classés ou se situent dans la marge, ce qui indique des performances plus médiocres.\n",
    "\n",
    "Résumé des résultats :\n",
    "\n",
    "Les valeurs de perte de charnière imprimées pour les deux modèles doivent être très proches (voire identiques), ce qui indique que les deux modèles fonctionnent de manière similaire dans la classification des données de test. Si elles diffèrent de manière significative, cela peut indiquer des différences dans la façon dont les modèles ont été formés ou dans la façon dont ils gèrent la limite de décision.\n",
    "\n",
    "Bon apprentissage !\n",
    "\n",
    "Salutations,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andreea Anghel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joseph Santarcangelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\">  Copyright &copy; 2021 IBM Corporation.  <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_env",
   "language": "python",
   "name": "projet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "prev_pub_hash": "3f8f93d5880dec3928c1a1a0753bb6ff77b98a9e4f7dde3af10b097f0c020d5c"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
